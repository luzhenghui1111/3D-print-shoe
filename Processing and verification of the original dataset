# ===== Cell 1 =====
import os, sys, numpy as np, pandas as pd, matplotlib
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import Matern, ConstantKernel, WhiteKernel
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, root_mean_squared_error

from scipy.optimize import fmin_l_bfgs_b  # è‡ªå®šä¹‰ä¼˜åŒ–å™¨ç”¨

RANDOM_STATE = 42
VAL_RATIO = 0.15
EXCEL_PATH = "æœºå™¨å­¦ä¹ 02.xlsx"   # â† æ”¹æˆä½ çš„æ–‡ä»¶å
SHEET_NAME = 0

print("Python:", sys.version.split()[0])
print("pandas:", pd.__version__)
print("numpy:", np.__version__)
print("matplotlib:", matplotlib.__version__)
import sklearn; print("scikit-learn:", sklearn.__version__)





# ===== Cell 2 =====
assert os.path.exists(EXCEL_PATH), f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶ï¼š{EXCEL_PATH}"
df_raw = pd.read_excel(EXCEL_PATH, sheet_name=SHEET_NAME)
print("âœ… è¯»å…¥æˆåŠŸï¼š", df_raw.shape)

ALIASES = {
    "A":["a"], "B":["b"], "C":["c","åšåº¦"], "P":["p","porosity"],
    "F":["f","force","è½½è·"], "X":["x"], "Y":["y"], "Z":["z"],
    "Dz":["dz"], "Dx":["dx"], "Dy":["dy"]
}
def find_col(k):
    if k in df_raw.columns: return k
    for alias in ALIASES.get(k, []):
        for c in df_raw.columns:
            if c.lower()==alias.lower(): return c
    return None

need = ["A","B","C","P","F","X","Y","Dz","Dx","Dy"]
opt  = ["Z"]
col_map = {k: find_col(k) for k in need+opt}
print("åˆ—æ˜ å°„ï¼š",col_map)

missing=[k for k,v in col_map.items() if k in need and v is None]
if missing: raise ValueError("ç¼ºåˆ—ï¼š"+str(missing))

use_cols=[v for v in col_map.values() if v is not None]
df=df_raw[use_cols].copy()
df.columns=[k for k,v in col_map.items() if v is not None]

# ä¸¢ç¼ºå¤±
df=df.dropna()
print("æ¸…ç†å:",df.shape)
if "Z" in df.columns and df["Z"].nunique()<=1:
    df=df.drop(columns=["Z"])
    print("å·²ä¸¢å¼ƒZåˆ—(å•å€¼)")

display(df.head())





# ===== Cell 3 =====
train_df,val_df=train_test_split(df,test_size=VAL_RATIO,
                                 random_state=RANDOM_STATE,shuffle=True)
print(f"è®­ç»ƒé›†:{len(train_df)} éªŒè¯é›†:{len(val_df)}")

def enc_angles_deg(arr):
    rad=np.deg2rad(arr.astype(float))
    return np.column_stack([np.sin(rad),np.cos(rad)])

def make_gpr_kernel():
    return ConstantKernel(1.0,(1e-3,1e3))*Matern(length_scale=1.0,nu=1.5)\
         +WhiteKernel(noise_level=1e-6,noise_level_bounds=(1e-12,1e-1))

# æ”¹è‰¯ä¼˜åŒ–å™¨ï¼šL-BFGS-B
def optimizer_lbfgsb(obj_func,theta,bounds):
    x,f,_=fmin_l_bfgs_b(obj_func,theta,bounds=bounds,maxiter=2000)
    return x,f





# ===== Cell 4 =====
print("Stage-1: æ­£åœ¨è®­ç»ƒ PÌ‚ æ¨¡å‹ (ABCâ†’P)...")
Xp_train=train_df[["A","B","C"]].to_numpy(float)
yp_train=train_df[["P"]].to_numpy(float)

sc_Xp=StandardScaler().fit(Xp_train)
sc_yp=StandardScaler().fit(yp_train)

gprP=GaussianProcessRegressor(
    kernel=make_gpr_kernel(),
    n_restarts_optimizer=5,
    random_state=RANDOM_STATE,
    normalize_y=False,
    optimizer=optimizer_lbfgsb,
    alpha=1e-10
)
gprP.fit(sc_Xp.transform(Xp_train),sc_yp.transform(yp_train).ravel())
print("âœ… Stage-1: è®­ç»ƒå®Œæˆ")





# ===== Cell 5 =====
print("Stage-2: æ­£åœ¨å‡†å¤‡è®­ç»ƒæ•°æ®...")
# è®­ç»ƒé›†(ç”¨çœŸå®P)
blocks=[
    train_df[["A","B","P","F"]].to_numpy(float),
    enc_angles_deg(train_df["X"].to_numpy()),
    enc_angles_deg(train_df["Y"].to_numpy())
]
use_Z = ("Z" in train_df.columns and train_df["Z"].nunique()>1)
if use_Z:
    blocks.append(enc_angles_deg(train_df["Z"].to_numpy()))
X_train_main=np.column_stack(blocks)

targets=["Dz","Dx","Dy"]
Y_train={t:train_df[[t]].to_numpy(float) for t in targets}

sc_X_main=StandardScaler().fit(X_train_main)
gprs,sc_y={},{}
print("Stage-2: æ­£åœ¨è®­ç»ƒ GPR æ¨¡å‹ (Dz/Dx/Dy)...")
for t in targets:
    sc_y[t]=StandardScaler().fit(Y_train[t])
    gprs[t]=GaussianProcessRegressor(
        kernel=make_gpr_kernel(),
        n_restarts_optimizer=3,
        random_state=RANDOM_STATE,
        normalize_y=False,
        optimizer=optimizer_lbfgsb,
        alpha=1e-10
    )
    gprs[t].fit(sc_X_main.transform(X_train_main),sc_y[t].transform(Y_train[t]).ravel())
print("âœ… Stage-2: è®­ç»ƒå®Œæˆ")

# éªŒè¯é›† (ç«¯åˆ°ç«¯: å…ˆç®—PÌ‚å†å…¥Stage-2)
print("Stage-2: æ­£åœ¨ç”ŸæˆéªŒè¯é›† PÌ‚...")
Xp_val=val_df[["A","B","C"]].to_numpy(float)
p_mean,_=gprP.predict(sc_Xp.transform(Xp_val),return_std=True)
p_hat_val=sc_yp.inverse_transform(p_mean.reshape(-1,1)).ravel()

blocks_val=[
    val_df[["A","B"]].to_numpy(float),
    p_hat_val.reshape(-1,1),
    val_df[["F"]].to_numpy(float),
    enc_angles_deg(val_df["X"].to_numpy()),
    enc_angles_deg(val_df["Y"].to_numpy())
]
if use_Z:
    blocks_val.append(enc_angles_deg(val_df["Z"].to_numpy()))
X_val_main=np.column_stack(blocks_val)
X_val_main_sc=sc_X_main.transform(X_val_main)

def _nice_limits(a, b, pad_ratio=0.05):
    lo, hi = float(min(a.min(), b.min())), float(max(a.max(), b.max()))
    pad = (hi - lo) * pad_ratio if hi > lo else 1.0
    return lo - pad, hi + pad

print("Stage-2: æ­£åœ¨éªŒè¯ Dz/Dx/Dy...")
for t in targets:
    mean_sc,std_sc=gprs[t].predict(X_val_main_sc,return_std=True)
    y_pred=sc_y[t].inverse_transform(mean_sc.reshape(-1,1)).ravel()
    y_true=val_df[t].to_numpy(float).ravel()
    residuals = y_true - y_pred

    R2=r2_score(y_true,y_pred)
    RMSE=root_mean_squared_error(y_true,y_pred)
    print(f"[Validation] {t}: RÂ²={R2:.4f}, RMSE={RMSE:.4f}")

    # æ®‹å·®ç›´æ–¹å›¾ï¼šç°è‰²è™šçº¿è¾¹æ¡† + æ–œçº¹
    plt.figure(figsize=(4.8, 3.2))
    n, bins, patches = plt.hist(residuals, bins=30)
    for p in patches:
        p.set_facecolor('none')
        p.set_edgecolor('0.4')
        p.set_linestyle('--')
        p.set_linewidth(1.2)
        p.set_hatch('////')
    plt.grid(alpha=0.25, linestyle=':', linewidth=0.8)
    plt.title(f"Residuals {t}")
    plt.xlabel("Residual"); plt.ylabel("Count")
    plt.tight_layout(); plt.show()

    # Parityï¼šä¸­ç©ºé»‘è¾¹å°åœ†ç‚¹
    plt.figure(figsize=(4.3, 4.3))
    plt.scatter(y_true, y_pred, s=26,
                facecolors='none', edgecolors='black', linewidths=0.8)
    lo, hi = _nice_limits(y_true, y_pred, 0.06)
    plt.plot([lo, hi], [lo, hi], linestyle='--', color='0.4', linewidth=1.0)
    plt.xlim(lo, hi); plt.ylim(lo, hi)
    plt.gca().set_aspect('equal', adjustable='box')
    plt.grid(alpha=0.25, linestyle=':', linewidth=0.8)
    plt.title(f"Parity {t}")
    plt.xlabel("True"); plt.ylabel("Predicted")
    plt.text(0.02, 0.98, f"RÂ²={R2:.3f}\nRMSE={RMSE:.3f}",
             transform=plt.gca().transAxes, ha='left', va='top', fontsize=9,
             bbox=dict(boxstyle='round,pad=0.25', fc='white', ec='0.7', alpha=0.9))
    plt.tight_layout(); plt.show()
print("âœ… Stage-2: éªŒè¯å®Œæˆ")





# ===== Cell 6 =====
# è¿ç»­åŒ–æ‰©å±•æ•°æ®é›†ï¼šæ–°æ ·æœ¬æ•° = åŸå§‹æ•°æ®é‡çš„10å€
N_NEW = len(df) * 10
SAVE_PATH = "æ‰©å±•æ•°æ®_é¢„æµ‹ç»“æœ.xlsx"   # æƒ³ä¿å­˜å°±ç•™ç€ï¼›ä¸ä¿å­˜è®¾ä¸º None

rng = np.random.default_rng(RANDOM_STATE)

# 1) è¿ç»­é‡‡æ · A, B, C
A_new = rng.uniform(1.0, 5.0, N_NEW)
B_new = rng.uniform(1.0, 5.0, N_NEW)
C_new = rng.uniform(1.5, 3.0, N_NEW)

# 2) Fã€è§’åº¦èŒƒå›´å–åŸæ•°æ®å®é™…èŒƒå›´
def _minmax(series):
    return float(series.min()), float(series.max())

F_lo, F_hi = _minmax(df["F"])
X_lo, X_hi = _minmax(df["X"])
Y_lo, Y_hi = _minmax(df["Y"])
Z_used = ("Z" in df.columns and df["Z"].nunique()>1)
if Z_used:
    Z_lo, Z_hi = _minmax(df["Z"])

F_new = rng.uniform(F_lo, F_hi, N_NEW)
X_new = rng.uniform(X_lo, X_hi, N_NEW)
Y_new = rng.uniform(Y_lo, Y_hi, N_NEW)
if Z_used:
    Z_new = rng.uniform(Z_lo, Z_hi, N_NEW)

# 3) ç”¨ Stage-1 è®¡ç®— PÌ‚(ABC)
ABC_sc = sc_Xp.transform(np.column_stack([A_new, B_new, C_new]))
P_hat_sc, _ = gprP.predict(ABC_sc, return_std=True)
P_new = sc_yp.inverse_transform(P_hat_sc.reshape(-1,1)).ravel()

# 4) ç»„è£… Stage-2 çš„è¾“å…¥å¹¶é¢„æµ‹ Dz/Dx/Dy
blocks_new = [
    np.column_stack([A_new, B_new, P_new, F_new]),
    enc_angles_deg(X_new),
    enc_angles_deg(Y_new),
]
if Z_used:
    blocks_new.append(enc_angles_deg(Z_new))
X_new_main = np.column_stack(blocks_new)
X_new_sc = sc_X_main.transform(X_new_main)

preds = {}
for t in ["Dz","Dx","Dy"]:
    mean_sc,_ = gprs[t].predict(X_new_sc, return_std=True)
    preds[t] = sc_y[t].inverse_transform(mean_sc.reshape(-1,1)).ravel()

# 5) æ±‡æˆ DataFrameï¼ˆæ‰©å±•æ•°æ®ï¼‰
cols = {
    "A":A_new, "B":B_new, "C":C_new, "P_hat":P_new,
    "F":F_new, "X":X_new, "Y":Y_new
}
if Z_used: cols["Z"] = Z_new
for t in ["Dz","Dx","Dy"]:
    cols[t+"_pred"] = preds[t]

new_df = pd.DataFrame(cols)
new_df["æ¥æº"] = "Extended"   # æ ‡è®°æ¥æº
print("âœ… è¿ç»­åŒ–æ‰©å±•æ•°æ®æ„å»ºå®Œæˆï¼š", new_df.shape)
display(new_df.head())

# 6) æ‹¼æ¥åŸå§‹æ•°æ® + æ‰©å±•æ•°æ®
df_for_concat = df.copy()
df_for_concat = df_for_concat.rename(columns={"P":"P_hat"})
for t in ["Dz","Dx","Dy"]:
    if t in df_for_concat.columns:
        df_for_concat = df_for_concat.rename(columns={t:t+"_pred"})
df_for_concat["æ¥æº"] = "Original"

all_df = pd.concat([df_for_concat, new_df], ignore_index=True)
print("ğŸ“¦ æ‹¼æ¥åçš„å®Œæ•´æ•°æ®ï¼š", all_df.shape)
display(all_df.head())

# 7) ä¿å­˜åˆ° Excel
if SAVE_PATH:
    with pd.ExcelWriter(SAVE_PATH, engine="openpyxl") as writer:
        new_df.to_excel(writer, index=False, sheet_name="Extended")
        all_df.to_excel(writer, index=False, sheet_name="All")
    print(f"ğŸ’¾ å·²ä¿å­˜åˆ°ï¼š{SAVE_PATH} (åŒ…å« Extended / All ä¸¤ä¸ªsheet)")
